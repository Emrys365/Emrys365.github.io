<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://emrys365.github.io/</id>
    <title>Speech 101</title>
    <updated>2022-06-06T13:46:15.476Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://emrys365.github.io/"/>
    <link rel="self" href="https://emrys365.github.io/atom.xml"/>
    <subtitle>记录、学习、分享语音相关知识</subtitle>
    <logo>https://emrys365.github.io/images/avatar.png</logo>
    <icon>https://emrys365.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, Speech 101</rights>
    <entry>
        <title type="html"><![CDATA[Debug 故事 01]]></title>
        <id>https://emrys365.github.io/post/debug-gu-shi-01</id>
        <link href="https://emrys365.github.io/post/debug-gu-shi-01">
        </link>
        <updated>2022-06-06T09:25:15.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>警告：为方便阅读，本文部分代码实为伪代码，请勿当真。</p>
</blockquote>
<h2 id="背景">背景</h2>
<p>最近我用 espnet 跑了一个比较慢的基线实验，采用 SNR loss 进行训练，虽然用上了单机 4 卡（2080ti）依然需要一周左右的时间才能完成。在基线的基础上，我希望调整一下模型训练过程，以便进行后续拓展：</p>
<ul>
<li>在计算 SNR loss 前对当前 batch 的标签进行判断，如果存在<strong>全零项</strong>，就用 L1 loss 函数来代替，因为 SNR loss 在标签为全零时无法计算。</li>
</ul>
<p>于是，我对原先的 loss 计算代码</p>
<pre><code class="language-python">loss, stats = 0.0, {}
...
loss_ = snr_loss(speech_ref, speech_pre)
stats_ = {&quot;snr_loss&quot;: loss_}
loss += loss_
stats.update(stats_)
</code></pre>
<p>做了如下修改：</p>
<pre><code class="language-python">loss, stats = 0.0, {}
...
has_all_zero = torch.cat(speech_ref, dim=0).sum(dim=-1).eq(0).any()
if has_all_zero:
    loss_ = l1_loss(speech_ref, speech_pre)
    stats_ = {&quot;l1_loss&quot;: loss_}
else:
    loss_ = snr_loss(speech_ref, speech_pre)
    stats_ = {&quot;snr_loss&quot;: loss_}
loss += loss_
stats.update(stats_)
</code></pre>
<h2 id="bug">Bug?</h2>
<p>上面的修改看似应该没有任何问题，于是我开始了模型训练。然而在检查模型的训练日志时，我发现了一个令人震惊的事实，那就是日志显示模型的 l1_loss 始终都是负的！这在理论上是绝不可能的，因为 L1 loss 是绝对值。</p>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<p>警告：为方便阅读，本文部分代码实为伪代码，请勿当真。</p>
</blockquote>
<h2 id="背景">背景</h2>
<p>最近我用 espnet 跑了一个比较慢的基线实验，采用 SNR loss 进行训练，虽然用上了单机 4 卡（2080ti）依然需要一周左右的时间才能完成。在基线的基础上，我希望调整一下模型训练过程，以便进行后续拓展：</p>
<ul>
<li>在计算 SNR loss 前对当前 batch 的标签进行判断，如果存在<strong>全零项</strong>，就用 L1 loss 函数来代替，因为 SNR loss 在标签为全零时无法计算。</li>
</ul>
<p>于是，我对原先的 loss 计算代码</p>
<pre><code class="language-python">loss, stats = 0.0, {}
...
loss_ = snr_loss(speech_ref, speech_pre)
stats_ = {&quot;snr_loss&quot;: loss_}
loss += loss_
stats.update(stats_)
</code></pre>
<p>做了如下修改：</p>
<pre><code class="language-python">loss, stats = 0.0, {}
...
has_all_zero = torch.cat(speech_ref, dim=0).sum(dim=-1).eq(0).any()
if has_all_zero:
    loss_ = l1_loss(speech_ref, speech_pre)
    stats_ = {&quot;l1_loss&quot;: loss_}
else:
    loss_ = snr_loss(speech_ref, speech_pre)
    stats_ = {&quot;snr_loss&quot;: loss_}
loss += loss_
stats.update(stats_)
</code></pre>
<h2 id="bug">Bug?</h2>
<p>上面的修改看似应该没有任何问题，于是我开始了模型训练。然而在检查模型的训练日志时，我发现了一个令人震惊的事实，那就是日志显示模型的 l1_loss 始终都是负的！这在理论上是绝不可能的，因为 L1 loss 是绝对值。</p>
<!-- more -->
<h2 id="debug">Debug</h2>
<p>考虑到日志显示的结果是对若干步训练结果的平均（1 个 iteration 大概包括 100 个 batch），于是我首先在上面修改的代码中插入了 print 语句来检验每个具体 batch 计算出的 L1 loss。结果也如预期般的正常，每一个打印出来的 L1 loss 值都是正的。这就与日志中的结果相矛盾了。</p>
<figure data-type="image" tabindex="1"><img src="https://emrys365.github.io//post-images/1654517186332.jpg" alt="无端联想" loading="lazy"></figure>
<p>此时我心中有一个巨大的疑惑：后续的代码中难道有任何操作会修改 stats 中的 loss 值吗？</p>
<p>乍一看似乎找不到这种操作，我只好从写日志的函数着手开始分析。因为最终写到训练日志中的 l1_loss 是不正常的，如果写日志的函数的输入输出值对应不上的话，很有可能就是它的问题！</p>
<figure data-type="image" tabindex="2"><img src="https://emrys365.github.io//post-images/1654518893713.png" alt="果然" loading="lazy"></figure>
<p>经过一番跳转可以找到，espnet 中模型训练的日志是通过类别 Reporter 的对象来输出的，它的 log_message 方法就是用来生成写到文件的日志信息。于是我在其中插入了一些 print 语句来探查输入的原始数据的值，得到的是如下的一串数字的列表：</p>
<pre><code class="language-python">l1_loss=[WeightedAverage(value=nan, weight=0), WeightedAverage(value=-0.835070
    788860321，weight=8), WeightedAverage(value=0.017597751691937447, weight=8),
    WeightedAverage(value=nan, weight=0), WeightedAverage(value=nan, weight=0),
    WeightedAverage(value=nan, weight=0), WeightedAverage(value=nan, weight=0),
    WeightedAverage(value=-1.290090799331665, weight=8), WeightedAverage(value=
    nan, weight=0), WeightedAverage(value=nan, weight=0), WeightedAverage(value=
    nan, weight=0), WeightedAverage(value=nan, weight=0), WeightedAverage(value=
    nan, weight=0), WeightedAverage(value=nan, weight=0), WeightedAverage(value=
    nan, weight=0), WeightedAverage(value=nan, weight=0), WeightedAverage(value=
    nan, weight=0), WeightedAverage(value=nan, weight=0), WeightedAverage(value=
    nan, weight=0), WeightedAverage(value=-0.5981062650680542, weight=8),
    ...
    WeightedAverage(value=0.014390362426638603, weight=8)]
</code></pre>
<blockquote>
<p>列表里的每个 WeightedAverage 对象的 value 就对应着一个 batch 内算出的 loss 平均值，weight 则代表该 batch 的 loss 权重（实际上等于 batch_size）。</p>
<p>最终日志输出的 l1_loss 标量值就是这些列表元素按各自权重的加权和，如果遇到 loss 值是 nan 则跳过。</p>
<p>列表里的那些权重为 0 的 nan 值实际上是代码添加的，目的是将 stats 字典的所有 key 对应的 value（都是列表）长度补齐到等长，即保证每个 batch 都有与之对应的一项数值。</p>
</blockquote>
<p>从上面的例子可以看出，日志系统在拿到“原始数据”的时候看到的已经是有正有负的 L1 loss 值了，因此 bug 应该在这一步之前就已经出现。</p>
<figure data-type="image" tabindex="3"><img src="https://emrys365.github.io//post-images/1654520310932.gif" alt="What?" loading="lazy"></figure>
<p>那么，究竟是哪一步操作导致 stats 中的 l1_loss 如此奇怪呢？</p>
<p>（其实原因早已经在前文中提到了……在继续往下翻之前，你不妨大胆猜想一下）</p>
<figure data-type="image" tabindex="4"><img src="https://emrys365.github.io//post-images/1654521156131.png" alt="优雅的分割线" loading="lazy"></figure>
<p>检查完了 loss 计算和写日志的代码，夹在它们中间的就只剩一些零碎的操作了，比如反向传播、优化器迭代、学习率调整等等。这些显然和 stats 的修改没有关系。</p>
<p>难道遗漏了什么？为了不错过任何一点蛛丝马迹，我打算从 loss 计算结束开始，逐行进行调查。很快啊，一个以 stats 作为输入和输出的函数引起了我的注意。</p>
<pre><code class="language-python">if ngpu &gt; 1 or distributed:
    # Apply weighted averaging for loss and stats
    loss = (loss * weight.type(loss.dtype)).sum()

    # if distributed, this method can also apply all_reduce()
    stats, weight = recursive_average(stats, weight, distributed)

    # Now weight is summation over all workers
    loss /= weight
</code></pre>
<p>这个 <code>recursive_average</code> 函数的特别之处在于，它的最后一个参数 <code>distributed</code> 意味着它和多机/多卡的运行环境有着紧密关系。</p>
<p>进一步跳转到它的定义</p>
<pre><code class="language-python">def recursive_average(obj, weight: torch.Tensor, distributed: bool = False):
    obj = recursive_sum(obj, weight, distributed)
    weight = weight.sum()
    if distributed:
        torch.distributed.all_reduce(weight, op=ReduceOp.SUM)
    # Normalize weight to be sum-to-1
    obj = recursive_divide(obj, weight)
    return obj, weight
</code></pre>
<p>就可以看到它的功能是对 stats 中所有的 value 列表的每一个元素都进行<strong>某种</strong>平均。可是对一个标量元素取平均有什么意义？</p>
<figure data-type="image" tabindex="5"><img src="https://emrys365.github.io//post-images/1654521809269.jpeg" alt="==" loading="lazy"></figure>
<p>这个函数针对的场景如果是多机/多卡的话……</p>
<p>看着 <code>recursive_average</code>, <code>recursive_sum</code>, <code>recursive_divide</code> 都出现的 <code>torch.distributed.all_reduce</code> 函数，我突然意识到，这些操作其实是对不同 GPU 上的对应数据（loss 值）进行聚合，那么平均就具有意义了。</p>
<p>同时，看到 all_reduce 这个熟悉的名词，我不禁回想起三年前《并行计算与并行算法》这门课上的学到的一些概念……我开始有了一些想法。</p>
<p>为了验证这个想法，我首先把实验设置换成了单卡，重新开始一次训练。几分钟后，我打开日志文件瞧了瞧，果然所有的 l1_loss 都恢复成了预期的正值。</p>
<figure data-type="image" tabindex="6"><img src="https://emrys365.github.io//post-images/1654518893713.png" alt="果然" loading="lazy"></figure>
<p>有了实验的验证，我开始按照新的想法修改起最初的代码：</p>
<pre><code class="language-python">loss, stats = 0.0, {}
...
has_all_zero = torch.cat(speech_ref, dim=0).sum(dim=-1).eq(0).any()
if has_all_zero:
    loss_l1 = l1_loss(speech_ref, speech_pre)
    loss_snr = loss_l1.new_zeros(())
    stats_ = {&quot;l1_loss&quot;: loss_l1, &quot;snr_loss&quot;: loss_snr}
else:
    loss_snr = snr_loss(speech_ref, speech_pre)
    loss_l1 = loss_snr.new_zeros(())
    stats_ = {&quot;l1_loss&quot;: loss_l1, &quot;snr_loss&quot;: loss_snr}
loss += loss_snr + loss_l1
stats.update(stats_)
</code></pre>
<p>再将实验设置改回 4 卡，重新进行训练。随着第一条 loss 日志的出现，我打消了心中的疑虑，同时也暗暗庆幸我当初决定采用 L1 loss 作为备选，而不是类似 SNR 的没有数值边界的 loss，不然这个 bug 恐怕要以更加诡异隐秘的形式出现了。</p>
<h2 id="揭开面纱">揭开面纱</h2>
<p>相信熟悉并行编程的读者此时已经猜到了这个 bug 的成因。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[提交 arXiv 文章的（LaTeX）预处理技巧]]></title>
        <id>https://emrys365.github.io/post/ti-jiao-arxiv-wen-zhang-de-latexyu-chu-li-ji-qiao</id>
        <link href="https://emrys365.github.io/post/ti-jiao-arxiv-wen-zhang-de-latexyu-chu-li-ji-qiao">
        </link>
        <updated>2020-10-27T03:57:19.000Z</updated>
        <content type="html"><![CDATA[<p>提交基于 tex 的文章时，可使用下列 shell 脚本进行处理，快速生成需要提交的文件：</p>
<blockquote>
<p>环境依赖：</p>
<ul>
<li>latexpand</li>
<li>pdflatex</li>
<li>bibtex</li>
</ul>
</blockquote>
<pre><code class="language-shell">#!/bin/bash

PS01=&quot;\033[01;35m\$\033[00m&quot;

echo -e &quot;\n${PS01} mv \033[4mmain.tex\033[0m \033[4mmain.tex.bak\033[0m&quot;
mv main.tex main.tex.bak
latexpand --empty-comments main.tex.bak &gt; main.tex
if [[ $OSTYPE == darwin* ]]; then
    sed -i '' -e '/^\s*%/d' main.tex
else
    sed -i -e '/^\s*%/d' main.tex
fi

echo -e &quot;\n${PS01} pdflatex \033[4mmain.tex\033[0m&quot;
pdflatex main.tex
echo -e &quot;\n${PS01} bibtex main&quot;
if [ -f &quot;main.bbl&quot; ]; then
    rm main.bbl
fi
bibtex main
echo -e &quot;\n${PS01} pdflatex \033[4mmain.tex\033[0m&quot;
pdflatex main.tex

echo -e &quot;\n${PS01} rm \033[4mmain{.aux,.log,.out}\033[0m&quot;
for suffix in .aux .blg .log .out; do
    if [ -f &quot;main${suffix}&quot; ]; then
        rm main${suffix}
    fi
done
echo -e &quot;#########################################################&quot;
echo -e &quot;\n(1) Please \033[33mcheck\033[0m and then \033[33mdelete\033[0m the generated \033[4mmain.pdf\033[0m.&quot;
echo -e &quot;\n(2) You \033[33mmust include\033[0m the following files in the archive:&quot;
echo -e &quot;  + main.tex\n  + main.bbl (or main.ind)\n  + referenced figures in main.tex\n  + (if applicable) other related tex files\n  + (optional) style file&quot;
echo -e &quot;\n(3) After removing \033[4mmain.pdf\033[0m, you can run the following&quot;
echo -e &quot;     command to generate the archive file:\n&quot;
# Below is an example. Must include all involved .tex files, figure files, style files, and main.bbl.
echo -e &quot;  zip -r to_arxiv.zip ./{INTERSPEECH2020.sty,acronyms.tex,figs,figs/*,main.bbl,main.tex}
echo -e &quot;\n#########################################################&quot;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ICASSP 历年最佳论文]]></title>
        <id>https://emrys365.github.io/post/icassp-li-nian-zui-jia-lun-wen</id>
        <link href="https://emrys365.github.io/post/icassp-li-nian-zui-jia-lun-wen">
        </link>
        <updated>2020-05-05T16:09:00.000Z</updated>
        <content type="html"><![CDATA[<h1 id="icassp">ICASSP</h1>
<ul>
<li>
<p>2020 年<br>
时间：2020年5月4日~8日<br>
地点：西班牙 巴塞罗那（虚拟会议）<br>
共收到  篇投稿，最终接收 2258 篇论文</p>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>The Empirical Duality Gap of Constrained Statistical Learning</td>
<td>Luiz F. O. Chamon, Santiago Paternain, Miguel Calvo-Fullana, Alejandro Ribeiro</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>2</td>
<td>Approximate Bayesian Computation with the Sliced-Wasserstein Distance</td>
<td>Kimia Nadjahi, Valentin De Bortoli, Alain Durmus, Roland Badeau, Umut Simsekli</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>3</td>
<td>Better safe than sorry: risk-aware nonlinear Bayesian estimation</td>
<td>Dionysios Kalogerias, Luiz Chamon, George Pappas, Alejandro Ribeiro</td>
<td>最佳论文</td>
</tr>
</tbody>
</table>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ASRU历年最佳论文]]></title>
        <id>https://emrys365.github.io/post/asru-li-nian-zui-jia-lun-wen</id>
        <link href="https://emrys365.github.io/post/asru-li-nian-zui-jia-lun-wen">
        </link>
        <updated>2019-12-25T15:34:55.000Z</updated>
        <content type="html"><![CDATA[<h1 id="asru">ASRU</h1>
<ul>
<li>
<p>2019 年<br>
时间：2019年12月14日~18日<br>
地点：新加坡 圣淘沙<br>
共收到 299 篇投稿，最终接收 144 篇论文</p>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Incremental Lattice Determinization For WFST Decoders</td>
<td>Zhehuai Chen, Mahsa Yarmohammadi, Hainan Xu, Hang Lv, Lei Xie, Daniel Povey, Sanjeev Khudanpur</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Integrating Source-Channel and Attention-Based Sequence-to-Sequence Models for Speech Recognition</td>
<td>Qiujia Li, Chao Zhang, and Philip C. Woodland</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>3</td>
<td>End-to-End Neural Speaker Diarization with Self-Attention</td>
<td>Yusuke Fujita, Naoyuki Kanda, Shota Horiguchi, Yawen Xue, Kenji Nagamatsu, Shinji Watanabe</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Orthogonality Constrained Multi-Head Attention for Keyword Spotting</td>
<td>Mingu Lee, Jinkyu Lee, Hye Jin Jang, Byeonggeun Kim, Wonil Chang, Kyuwoong Hwang</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>MIMO-Speech: End-to-End Multi-Channel Multi-Speaker Speech Recognition</td>
<td>Xuankai Chang, Wangyou Zhang, Yanmin Qian, Jonathan Le Roux, Shinji Watanabe</td>
<td>最佳论文</td>
</tr>
<tr>
<td>6</td>
<td>Speaker and Language Aware Training for End-to-End ASR</td>
<td>Shubham Bansal, Karan Malhotra, Sriram Ganapathy</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>CNN with Phonetic Attention for Text-Independent Speaker Verification</td>
<td>Tianyan Zhou, Yong Zhao, Jinyu Li, Yifan Gong, Jian Wu</td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>2017 年<br>
时间：2017年12月16日~20日<br>
地点：日本 冲绳县<br>
共收到 ? 篇投稿，最终接收 106 篇论文</p>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Streaming Small-Footprint Keyword Spotting Using Sequence-to-Sequence Models</td>
<td>Yanzhang He, Rohit Prabhavalkar, Kanishka Rao, Wei Li, Anton Bakhtin, Ian McGraw</td>
<td>最佳论文</td>
</tr>
<tr>
<td>2</td>
<td>Hierarchical Recurrent Neural Network for Story Segmentation Using Fusion of Lexical and Acoustic Features</td>
<td>Emiru Tsunoo, Ondrej Klejch, Peter Bell, Steve Renals</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>An Embedded Segmental K-Means Model for Unsupervised Segmentation and Clustering of Speech</td>
<td>Herman Kamper, Karen Livescu, Sharon Goldwater</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Composite Embedding Systems for Zerospeech2017 Track1</td>
<td>Hayato Shibata, Taku Kato, Takahiro Shinozaki, Shinji Watanabe</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Exploring Architectures, Data and Units for Streaming End-to-End Speech Recognition with RNN-Transducer</td>
<td>Kanishka Rao, Hasim Sak, Rohit Prabhavalkar</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>Exploring Neural Transducers for End-to-End Speech Recognition</td>
<td>Eric Battenberg, Jitong Chen, Rewon Child, Adam Coates, Yashesh Gaur, Yi Li, Hairong Liu, Sanjeev Satheesh, Anuroop Sriram, Zhenyao Zhu</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Unsupervised Adaptation with Domain Separation Networks for Robust Speech Recognition</td>
<td>Zhong Meng, Zhuo Chen, Vadim Mazalov, Jinyu Li, Yifan Gong</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Language Independent End-to-End Architecture for Joint Language Identification and Speech Recognition</td>
<td>Shinji Watanabe, Takaaki Hori, John Hershey</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Multi-Level Language Modeling and Decoding for Open Vocabulary End-to-End Speech Recognition</td>
<td>Takaaki Hori, Shinji Watanabe, John Hershey</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>Listening While Speaking: Speech Chain by Deep Learning</td>
<td>Andros Tjandra, Sakriani Sakti, Satoshi Nakamura</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>11</td>
<td>Unsupervised Domain Adaptation for Robust Speech Recognition Via Variational Autoencoder-Based Data Augmentation</td>
<td>Wei-Ning Hsu, Yu Zhang, James Glass</td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>2015 年</p>
<p>时间：2015年12月13日~17日<br>
地点：美国 斯科茨代尔<br>
共收到 224 篇投稿，最终接收 107 篇论文</p>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Hybrid DNN-Latent Structured SVM Acoustic models for Continuous Speech Recognition</td>
<td>Suman Ravuri</td>
<td>最佳论文</td>
</tr>
<tr>
<td>2</td>
<td></td>
<td></td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>3</td>
<td>EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding</td>
<td>Yajie Miao, Mohammad Gowayyed, Florian Metze</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Policy Committee for Adaptation in Multi-Domain Spoken Dialogue Systems</td>
<td>M. Gašić, N. Mrkšić, Pei-hao Su, David Vandyke, Tsung-Hsien Wen, Steve Young</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>(待补充)</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>2013 年</p>
<p>时间：2013年12月8日~13日<br>
地点：捷克 奥洛穆茨</p>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Unsupervised Induction and Filling of Semantic Slots for Spoken Dialogue Systems using Frame-Semantic Parsing</td>
<td>Yun-Nung Chen, William Yang Wang, Alexander I. Rudnicky</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>2</td>
<td>A Hierarchical System for Word Discovery Exploiting Dtw-Based Initialization</td>
<td>Oliver Walter, Timo Korthals, Reinhold Haeb-Umbach, Bhiksha Raj</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>3</td>
<td>The Tao of ATWV: Probing the Mysteries of Keyword Search Performance</td>
<td>Steven Wegmann, Arlo Faria, Adam Janin, Korbinian Riedhammer, Nelson Morgan</td>
<td>最佳论文</td>
</tr>
<tr>
<td>4</td>
<td>Convolutional Neural Network Based Triangular CRF for Joint Intent Detection and Slot Filling</td>
<td>Puyang Xu, Ruhi Sarikaya</td>
<td>最佳论文</td>
</tr>
<tr>
<td>5</td>
<td>(待补充)</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>2011 年</p>
<p>时间：2011年12月11日~15日<br>
地点：美国 夏威夷岛</p>
</li>
<li>
<p>2009 年</p>
<p>时间：2009年12月13日~17日<br>
地点：意大利 梅拉诺</p>
</li>
<li>
<p>2007 年</p>
<p>时间：2007年12月9日~13日<br>
地点：日本 京都</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[InterSpeech历年最佳论文]]></title>
        <id>https://emrys365.github.io/post/interspeech-li-nian-zui-jia-lun-wen</id>
        <link href="https://emrys365.github.io/post/interspeech-li-nian-zui-jia-lun-wen">
        </link>
        <updated>2019-12-25T08:15:11.000Z</updated>
        <content type="html"><![CDATA[<h1 id="interspeech">InterSpeech</h1>
<p>（主要数据来源：每年会议的 AbstractBook.pdf）</p>
<ul>
<li>2020 年<br>
时间：2020年10月25日~29日<br>
地点：中国 上海（远程会议）<br>
共收到 2258 篇投稿，其中 2103 篇被审稿，最终接收 1021 篇论文</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Nonlinear ISA with Auxiliary Variables for Learning Speech Representations</td>
<td>Amrith Setlur, Barnabas Poczos, Alan W Black</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Low Latency End-to-End Streaming Speech Recognition with a Scout Network</td>
<td>Chengyi Wang, Yu Wu, Liang Lu, Shujie Liu, Jinyu Li, Guoli Ye, Ming Zhou</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>A Differentiable Perceptual Audio Metric Learned from Just Noticeable Differences</td>
<td>Pranay Manocha, Adam Finkelstein, Richard Zhang, Nicholas Bryan, Gautham Mysore, Zeyu Jin</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Speaker discrimination in humans and machines: Effects of speaking style variability</td>
<td>Amber Afshan, Jody Kreiman, Abeer Alwan</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>FaceFilter: Audio-visual speech separation using still images</td>
<td>Soo-Whan Chung, Soyeon Choe, Joon Son Chung, Hong-Goo Kang</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>6</td>
<td>ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification</td>
<td>Brecht Desplanques, Jenthe Thienpondt, Kris Demuynck</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Distilling the Knowledge of BERT for Sequence-to-Sequence ASR</td>
<td>Hayato Futami, Hirofumi Inaguma, Sei Ueno, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Vector-Quantized Autoregressive Predictive Coding</td>
<td>Yu-An Chung, Hao Tang, James Glass</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>9</td>
<td>Automatic Detection of Phonological Errors in Child Speech Using Siamese Recurrent Autoencoder</td>
<td>Si-Ioi Ng, Tan Lee</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>Phonetic Accommodation of L2 German Speakers to the Virtual Language Learning Tutor Mirabella</td>
<td>Iona Gessinger, Bernd Möbius, Bistra Andreeva, Eran Raveh, Ingmar Steiner</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>11</td>
<td>Abstractive Spoken Document Summarization using Hierarchical Model with Multi-stage Attention Diversity Optimization</td>
<td>Potsawee Manakul, Mark Gales, Linlin Wang</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>2019 年<br>
时间：2019年9月15日~19日<br>
地点：奥地利 格拉茨<br>
共收到 2180 篇投稿，其中 1855 篇被审稿，最终接收 914 篇论文</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>ReMASC: Realistic Replay Attack Corpus for Voice Controlled Systems</td>
<td>Yuan Gong, Jian Yang, Jacob Huber, Mitchell MacKnight, Christian Poellabauer</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Curriculum-Based Transfer Learning for an Effective End-to-End Spoken Language Understanding and Domain Portability</td>
<td>Antoine Caubrière, Natalia Tomashenko, Antoine Laurent, Emmanuel Morin, Nathalie Camelin and Yannick Estève</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>Learning Problem-agnostic Speech Representations from Multiple Self-supervised Tasks</td>
<td>Santiago Pascual, Mirco Ravanelli, Joan Serrà, Antonio Bonafonte and Yoshua Bengio</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Evaluating Near End Listening Enhancement Algorithms in Realistic Environments</td>
<td>Carol Chermaz, Cassia Valentini-Botinhao, Henning Schepker, Simon King</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>5</td>
<td>Adversarially Trained End-to-end Korean Singing Voice Synthesis System</td>
<td>Juheon Lee, Hyeong-Seok Choi, Chang-Bin Jeon, Junghyun Koo, Kyogu Lee</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>6</td>
<td>The Contribution of Acoustic Features Analysis to Model Emotion Perceptual Process for Language Diversity</td>
<td>Xingfeng Li, Masato Akagi</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>CycleGAN-based Emotion Style Transfer as Data Augmentation for Speech Emotion Recognition</td>
<td>Fang Bao, Michael Neumann, Ngoc Thang Vu</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Exploiting Visual Features using Bayesian Gated Neural Networks for Disordered Speech Recognition</td>
<td>Shansong Liu, Shoukang Hu, Yi Wang, Jianwei Yu, Rongfeng Su, Xunying Liu, Helen Meng</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>On the Role of Style in Parsing Speech with Neural Models</td>
<td>Trang Tran, Jiahong Yuan, Yang Liu, Mari Ostendorf</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>An Effective Deep Embedding Learning Architecture for Speaker Verification</td>
<td>Yiheng Jiang, Yan Song, Ian McLoughlin, Zhifu Gao, Lirong Dai</td>
<td></td>
</tr>
<tr>
<td>11</td>
<td>Towards the Speech Features of Mild Cognitive Impairment: Universal Evidence from Structured and Unstructured Connected Speech of Chinese</td>
<td>Tianqi Wang, Chongyuan Lian, Jingshen Pan, Quanlei Yan, Feiqi Zhu, Manwa L. Ng, Lan Wang,Nan Yan</td>
<td></td>
</tr>
<tr>
<td>12</td>
<td>Semi-supervised Sequence-to-sequence ASR using Unpaired Speech and Text</td>
<td>Murali Karthick Baskar, Shinji Watanabe, Ramón Astudillo, Takaaki Hori, Lukas Burget, Jan Černocký</td>
<td></td>
</tr>
<tr>
<td>13</td>
<td>Language Modeling with Deep Transformers</td>
<td>Kazuki Irie, Albert Zeye, Ralf Schlüter, Hermann Ney</td>
<td>最佳学生论文</td>
</tr>
</tbody>
</table>
<ul>
<li>2018 年<br>
时间：2018年9月2日~6日<br>
地点：印度 海得拉巴<br>
共收到 1668 篇投稿，最终接收 749 篇论文</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Automatic Glottis Localization and Segmentation in Stroboscopic Videos Using Deep Neural Network</td>
<td>Achuth Rao M V, Rahul Krishnamurthy, Pebbili Gopikishore, Veeramani Priyadharshini, Prasanta Kumar Ghosh</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Effects of User Controlled Speech Rate on Intelligibility in Noisy Environments</td>
<td>John S. Novak, III, Robert V. Kenyon</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>An Interlocutor-Modulated Attentional LSTM for Differentiating between Subgroups of Autism Spectrum Disorder</td>
<td>Yun-Shao Lin, Susan Shur-Fen Ga, Chi-Chun Lee</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>An Improved Deep Embedding Learning Method for Short Duration Speaker Verification</td>
<td>Zhifu Gao, Yan Song, Ian McLoughlin, Wu Guo, Lirong Dai</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Joint Localization and Classification of Multiple Sound Sources Using a Multi-task Neural Network</td>
<td>Weipeng He, Petr Motlicek, Jean-Marc Odobez</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>A Priori SNR Estimation Based on a Recurrent Neural Network for Robust Speech Enhancement</td>
<td>Yangyang Xia and Richard M. Stern</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Multi-target Voice Conversion without Parallel Data by Adversarially Learning Disentangled Audio Representations</td>
<td>Ju-chieh Chou, Cheng-chieh Yeh, Hung-yi Lee and Lin-shan Lee</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Multi-Modal Data Augmentation for End-to-End ASR</td>
<td>Adithya Renduchintala, Shuoyang Ding, Matthew Wiesner and Shinji Watanabe</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>9</td>
<td>A GPU-based WFST Decoder with Exact Lattice Generation</td>
<td>Zhehuai Chen, Justin Luitjens, Hainan Xu, Yiming Wang, Daniel Povey and Sanjeev Khudanpur</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>User-centric Evaluation of Automatic Punctuation in ASR Closed Captioning</td>
<td>Ákos Máté Tündik, György Szaszák, Gábor Gosztolya and András Bek</td>
<td></td>
</tr>
<tr>
<td>11</td>
<td>Detecting Depression with Audio/Text Sequence Modeling of Interview</td>
<td>Tuka Alhanai, Mohammad Ghassemi and James Glass</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>12</td>
<td>Joint Learning of Interactive Spoken Content Retrieval and Trainable User Simulator</td>
<td>Pei-Hung Chung, Kuan Tung, Ching-Lun Tai and Hung-Yi Lee</td>
<td>最佳学生论文</td>
</tr>
</tbody>
</table>
<ul>
<li>2017 年<br>
时间：2017年8月20日~24日<br>
地点：瑞典 斯德哥尔摩<br>
共收到 1711 篇投稿，其中 1582 篇被审稿，最终接收 799 篇论文</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Relating Unsupervised Word Segmentation to Reported Vocabulary Acquisition</td>
<td>Elin Larsen, Alejandrina Cristia, Emmanuel Dupoux</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Mind the Peak: When Museum Is Temporarily Understood as Musical in Australian English</td>
<td>Katharina Zahner, Heather Kember, Bettina Braun</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>Jointly Predicting Arousal, Valence and Dominance with Multi-Task Learning</td>
<td>Srinivas Parthasarathy, Carlos Busso</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>VoxCeleb: A Large-scale Speaker Identification Dataset</td>
<td>Arsha Nagrani, Joon Son Chung, Andrew Zisserman</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>5</td>
<td>Hidden Markov Model Variational Autoencoder for Acoustic Unit Discovery</td>
<td>Janek Ebbers, Jahn Heymann, Lukas Drude, Thomas Glarner, Reinhold Haeb-Umbach, Bhiksha Raj</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>6</td>
<td>Tight Integration of Spatial and Spectral Features for BSS with Deep Clustering Embeddings</td>
<td>Lukas Drude, Reinhold Haeb-Umbach</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>VCV Synthesis using Task Dynamics to Animate a Factor-based Articulatory Model</td>
<td>Rachel Alexander, Tanner Sorensen, Asterios Toutios, Shrikanth Narayanan</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>CTC in the Context of Generalized Full-Sum HMM Training</td>
<td>Albert Zeyer, Eugen Beck, Ralf Schlüter, Hermann Ney</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Residual Memory Networks in Language Modeling: Improving the Reputation of Feed-Forward Networks</td>
<td>Karel Beneš, Murali Baskar, Lukáš Burget</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>10</td>
<td>Experiments in Character-level Neural Network Models for Punctuation</td>
<td>William Gale, Sarangarajan Parthasarathy</td>
<td></td>
</tr>
<tr>
<td>11</td>
<td>Entrainment in Multi-Party Spoken Dialogues at Multiple Linguistic Levels</td>
<td>Zahra Rahimi, Anish Kumar, Diane Litman, Susannah Paletz, Mingzhi Yu</td>
<td></td>
</tr>
<tr>
<td>12</td>
<td>Topic Identification for Speech without ASR</td>
<td>Chunxi Liu, Jan Trmal, Matthew Wiesner, Craig Harman, Sanjeev Khudanpur</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>2016 年<br>
时间：2016年9月8日~12日<br>
地点：美国 旧金山<br>
共收到 1644 篇投稿，其中 1585 篇被审稿，最终接收 779 篇论文</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Characterizing Vocal Tract Dynamics Across Speakers Using Real-Time MRI</td>
<td>Tanner Sorensen, Asterios Toutios, Louis Goldstein, Shrikanth Narayanan</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>2</td>
<td>Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine</td>
<td>Bo-Hsiang Tseng, Sheng-Syun Shen, Hung-Yi Lee, Lin-Shan Lee</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>A DNN-HMM Approach to Story Segmentation</td>
<td>Jia Yu, Xiong Xiao, Lei Xie, Eng Siong Chng, Haizhou Li</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Head Motion Generation with Synthetic Speech: A Data Driven Approach</td>
<td>Najmeh Sadoughi, Carlos Busso</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>The Rhythmic Constraint on Prosodic Boundaries in Mandarin Chinese Based on Corpora of Silent Reading and Speech Perception</td>
<td>Wei Lai, Jiahong Yuan, Ya Li, Xiaoying Xu, Mark Liberman</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>6</td>
<td>Is Deception Emotional? An Emotion-Driven Predictive Approach</td>
<td>Shahin Amiriparian, Jouni Pohjalainen, Erik Marchi, Sergey Pugachevskiy, Björn Schuller</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Probabilistic Approach Using Joint Clean and Noisy I-Vectors Modeling for Speaker Recognition</td>
<td>Waad Ben Kheder, Driss Matrouf, Ajili Moez, Jean-François Bonastre</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Majorisation-Minimisation Based Optimisation of the Composite Autoregressive System with Application to Glottal Inverse Filtering</td>
<td>Lauri Juvela, Hirokazu Kameoka, Manu Airaksinen, Junichi Yamagishi, Paavo Alku</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Local Sparsity Based Online Dictionary Learning for Environment-Adaptive Speech Enhancement with Nonnegative Matrix Factorization</td>
<td>Kwang Myung Jeon, Hong Kook Kim</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>GlottDNN - A Full-Band Glottal Vocoder for Statistical Parametric Speech Synthesis</td>
<td>Manu Airaksinen, Bajibabu Bollepalli, Lauri Juvela, Zhizheng Wu, Simon King, Paavo Alku</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>11</td>
<td>Stimulated Deep Neural Network for Speech Recognition</td>
<td>Chunyang Wu, Penny Karanasou, Mark Gales, Khe Chai Sim</td>
<td></td>
</tr>
<tr>
<td>12</td>
<td>Contextual Prediction Models for Speech Recognition</td>
<td>Yoni Halpern, Keith Hall, Vlad Schogol, Michael Riley, Brian Roark, Gleb Skobeltsyn, Martin Baeuml</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>2015 年<br>
时间：2015年9月6日~10日<br>
地点：德国 德累斯顿<br>
共 1458 篇被审稿，最终接收 746 篇论文</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Low-Frequency Components Analysis in Running Speech for the Automatic Detection of Parkinson's Disease</td>
<td>T. Villa-Cañas, J.D. Arias-Londoño, J.R. Orozco-Arroyave, J.F. Vargas-Bonilla, E. Nöth</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Speech Planning in 4-Year-Old Children Versus Adults: Acoustic and Articulatory Analyses</td>
<td>Guillaume Barbier, Pascal Perrier, Lucie Ménard, Yohan Payan, Mark Tiede, Joseph Perkell</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>Using Representation Learning and Out-of-Domain Data for a Paralinguistic Speech Task</td>
<td>Benjamin Milde, Chris Biemann</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Under-Resourced Speech Recognition Based on the Speech Manifold</td>
<td>Reza Sahraeian, Dirk Van Compernolle, Febe de Wet</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Estimation of the Air-Tissue Boundaries of the Vocal Tract in the Mid-Sagittal Plane from Electromagnetic Articulograph Data</td>
<td>Satyabrata Parida, Pattem Ashok Kumar, Prasanta Kumar Ghosh</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>Adapting Machine Translation Models toward Misrecognized Speech with Text-To-Speech Pronunciation Rules and Acoustic Confusability</td>
<td>Nicholas Ruiz, Qin Gao, William Lewis, Marcello Federico</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>7</td>
<td>A Universal VAD Based on Jointly Trained Deep Neural Networks</td>
<td>Qing Wang, Jun Du, Xiao Bao, Zi-Rui Wang, Li-Rong Dai, Chin-Hui Lee</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Semi-supervised Maximum Mutual Information Training of Deep Neural Network Acoustic Models</td>
<td>Vimal Manohar, Daniel Povey, Sanjeev Khudanpur</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Salient Dimensions in Implicit Phonotactic Learning</td>
<td>Elise Michon, Emmanuel Dupoux , Alejandrina Cristia</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>A Time Delay Neural Network Architecture for Efficient Modeling of Long Temporal Contexts</td>
<td>Vijayaditya Peddinti, Daniel Povey, Sanjeev Khudanpur</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>11</td>
<td>Representing Nonspeech Audio Signals through Speech Classification Models</td>
<td>Huy Phan, Lars Hertel, Marco Maass, Radoslaw Mazur, Alfred Mertins</td>
<td></td>
</tr>
<tr>
<td>12</td>
<td>Objective Intelligibility Assessment of Text-To-Speech Systems through Utterance Verification</td>
<td>Raphael Ullmann, Ramya Rasipuram, Mathew Magimai.-Doss, Hervé Bourlard</td>
<td>最佳学生论文</td>
</tr>
</tbody>
</table>
<ul>
<li>2014 年<br>
时间：2014年9月14日~18日<br>
地点：新加坡<br>
共 1173 篇被审稿，最终接收 614 篇论文</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Investigating the Effect of F0 and Vocal Intensity on Harmonic Magnitudes: Data from Laryngeal High-Speed Video Endoscopy</td>
<td>Gang Chen, Soo Jin Park, Jody Kreiman, Abeer Alwan</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Automatic Estimation of the Lip Radiation Effect in Glottal Inverse Filtering</td>
<td>Manu Airaksinen, Tom Bäckström, Paavo Alku</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>Modeling Therapist Empathy through Prosody in Drug Addiction Counseling</td>
<td>Bo Xiao, Daniel Bone, Maarten Van Segbroeck, Zac Imel, David Atkins, Panayiotis Georgiou, Shrikanth Narayanan</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Intrinsic Spectral Analysis Based on Temporal Context Features for Query by Example Spoken Term Detection</td>
<td>Peng Yang, Cheung-Chi Leung, Lei Xie, Bin Ma, Haizhou Li</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Direct F0 Control of an Electrolarynx Based on Statistical Excitation Feature Prediction and Its Evaluation through Simulation</td>
<td>Tomoki Toda, Graham Neubig, Sakriani Sakti, Satoshi Nakamura, Ko Tanaka</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>Towards a Neural Measure of Perceptual Distance - Classification of Electroencephalographic Responses to Synthetic Vowels</td>
<td>Manson Cheuk-Man Fong, James William Minett, Thierry Blu, William Shi-Yuan Wang</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Exploring Modulation Spectrum Features for Speech-Based Depression Level Classification</td>
<td>Elif Bozkurt, Orith Toledo - Ronen, Alexander Sorin, Ron Hoory</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Lexical Representation of Consonant, Vowels and Tones in Early Childhood</td>
<td>Hwee Hwee Goh, Charlene Fu, Kheng Hui Yeo</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Speech Synthesis in Various Communicative Situations: Impact of Pronunciation Variations</td>
<td>Sandrine Brognaux, Benjamin Picart, Thomas Drugman</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>10</td>
<td>Adaptive Speech Recognition and Dialogue Management for Users with Speech Disorders</td>
<td>Iñigo Casanueva, Heidi Christensen, Thomas Hain, Phil Green</td>
<td></td>
</tr>
<tr>
<td>11</td>
<td>Word-level Invariant Representations from Acoustic Waveforms</td>
<td>Stephen Voinea, Chiyuan Zhang, Georgios Evangelopoulos, Lorenzo Rosasco, Tomaso Poggio</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>12</td>
<td>Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR</td>
<td>Zoltán Tüske, Pavel Golik, Ralf Schlüter, Hermann Ney</td>
<td>最佳学生论文</td>
</tr>
</tbody>
</table>
<ul>
<li>2013 年<br>
时间：2013年9月14日~18日<br>
地点：法国 里昂</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文</th>
<th>作者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Speaker and Noise Independent Voice Activity Detection</td>
<td>François Germain, Dennis Sun, Gautham Mysore</td>
</tr>
<tr>
<td>2</td>
<td>A Two-Step Technique for MRI Audio Enhancement Using Dictionary Learning and Wavelet Packet Analysis</td>
<td>Colin Vaz, Vikram Ramanarayanan, Shrikanth Narayanan</td>
</tr>
<tr>
<td>3</td>
<td>Using Text and Acoustic Features to Diagnose Progressive Aphasia and Its Subtypes</td>
<td>Kathleen Fraser, Frank Rudzicz, Elizabeth Rochon</td>
</tr>
</tbody>
</table>
<ul>
<li>2012 年<br>
时间：2012年9月9日~13日<br>
地点：美国 波特兰</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文</th>
<th>作者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Discriminatively Learning Factorized Finite State Pronunciation Models from Dynamic Bayesian Networks</td>
<td>Preethi Jyothi, Eric Fosler-Lussier, Karen Livescu</td>
</tr>
<tr>
<td>2</td>
<td>MAP Estimation of Whole-Word Acoustic Models with Dictionary Priors</td>
<td>Keith Kintzley, Aren Jansen, Hynek Hermansky</td>
</tr>
<tr>
<td>3</td>
<td>Age Estimation from Telephone Speech using i-vectors</td>
<td>Mohamad Hasan Bahari, Mitchell McLaren, Hugo Van hamme, David Van Leeuwen</td>
</tr>
</tbody>
</table>
<ul>
<li>2011 年<br>
时间：2011年8月27日~31日<br>
地点：意大利 佛罗伦萨</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文</th>
<th>作者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Low-Frequency Bandwidth Extension of Telephone Speech Using Sinusoidal Synthesis and Gaussian Mixture Model</td>
<td>Hannu Pulakka, Ulpu Remes, Santeri Yrttiaho, Kalle Palomäki, Mikko Kurimo, Paavo Alku</td>
</tr>
<tr>
<td>2</td>
<td>One-to-Many Voice Conversion Based on Tensor Representation of Speaker Space</td>
<td>Daisuke Saito, Keisuke Yamamoto, Nobuaki Minematsu, Keikichi Hirose</td>
</tr>
<tr>
<td>3</td>
<td>Modelling Novelty Preference in Word Learning</td>
<td>Maarten Versteegh, Louis ten Bosch, Lou Boves</td>
</tr>
</tbody>
</table>
<ul>
<li>2010 年<br>
时间：2010年9月26日~30日<br>
地点：日本 千葉市</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文</th>
<th>作者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Did you say susi or shushi? Measuring the Emergence of Robust Fricative Contrasts in English- and Japanese-Acquiring Children</td>
<td>Jeffrey J. Holliday, Mary E. Beckman, Chanelle Mays</td>
</tr>
<tr>
<td>2</td>
<td>Using Non-Native Error Patterns to Improve Pronunciation Verification</td>
<td>Joost van Doremalen, Catia Cucchiarini, Helmer Strik</td>
</tr>
<tr>
<td>3</td>
<td>Reliable Tracking Based on Speech Sample Salience of Vocal Cycle Length Perturbations</td>
<td>Christophe Mertens, Francis Grenez, Lise Crevier-Buchman, Jean Schoentgen</td>
</tr>
</tbody>
</table>
<ul>
<li>2009 年<br>
时间：2009年9月6日~10日<br>
地点：英国 布莱顿</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文</th>
<th>作者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Sequencing of Articulatory Gestures using Cost Optimization</td>
<td>Juraj Simko, F. Cummins.</td>
</tr>
<tr>
<td>2</td>
<td>A Deterministic plus Stochastic Model of the Residual Signal for Improved Parametric Speech Synthesis</td>
<td>Thomas Drugman, G. Wilfart, T.Dutoit</td>
</tr>
<tr>
<td>3</td>
<td>On the Semi-Supervised Learning of Multi-Layered Perceptrons</td>
<td>Jonathan Malkin, Amarnag Subramanya, J. Bilmes</td>
</tr>
</tbody>
</table>
<ul>
<li>2008 年<br>
时间：2008年9月22日~26日<br>
地点：澳大利亚 布里斯班</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文</th>
<th>作者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>On the Equivalence of Gaussian and Log-linear HMMS</td>
<td>Georg Heigold, Lehnen, P., Schlueter, R., Ney, H.</td>
</tr>
<tr>
<td>2</td>
<td>Combining Continuous Progressive Model Adaptation and Factor Analysis for Speaker Verification</td>
<td>Mitchell McLaren, Matrouf, D., Vogt R., Bonastre, J.</td>
</tr>
<tr>
<td>3</td>
<td>Effect of Intonational Phrase Boundaries on Pitch-Accented Syllables in American English</td>
<td>Yen-Liang Shue, Shuttuck-Hufnagel, S., Iseli, M., Jun S., Veilleux N., Alwan, A.</td>
</tr>
</tbody>
</table>
<ul>
<li>2007 年<br>
时间：2007年8月27日~31日<br>
地点：比利时 安特卫普</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文</th>
<th>作者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Speech Recognition Techniques for a Sign Language Recognition System</td>
<td>Philippe Dreuw, David Rybach, Thomas Deselaers, Morteza Zahedi, Hermann Ney</td>
</tr>
<tr>
<td>2</td>
<td>An Empirical Investigation of the Nonuniqueness in the Acoustic-to-Articulatory Mapping</td>
<td>Chao Qin, Miguel A. Carreira-Perpinan</td>
</tr>
</tbody>
</table>
<ul>
<li>2006 年<br>
时间：2006年9月17日~21日<br>
地点：美国 匹兹堡</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文</th>
<th>作者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Detecting Question-Bearing Turns in Spoken Tutorial Dialogues</td>
<td>Jackson Liscombe, Jennifer J. Venditti, Julia Hirschberg</td>
</tr>
<tr>
<td>2</td>
<td>Soft Margin Estimation of Hidden Markov Model Parameters</td>
<td>Jinyu Li, Ming Yuan, Chin-Hui Lee</td>
</tr>
<tr>
<td>3</td>
<td>Acoustic Cues for the Classification of Regular and Irregular Phonation</td>
<td>Kushan Surana, Janet Slifka</td>
</tr>
</tbody>
</table>
<ul>
<li>2005 年<br>
时间：2005年9月4日~8日<br>
地点：葡萄牙 里斯本</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文</th>
<th>作者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>On the Integration of Speech Recognition and Statistical Machine Translation</td>
<td>E. Matusov, S. Kanthak, H. Ney.</td>
</tr>
</tbody>
</table>
<ul>
<li>2004 年<br>
时间：2004年10月4日~8日<br>
地点：韩国 济州岛</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文</th>
<th>作者</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Hot Discussion or Frosty Dialogue? Towards a Temperature Metric for Conversational Interactivity</td>
<td>Peter Reichl, Florian Hammer</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
</feed>