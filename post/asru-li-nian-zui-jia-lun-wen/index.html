<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>ASRU历年最佳论文 | Speech 101</title>
<meta name="description" content="记录、学习、分享语音相关知识">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="shortcut icon" href="https://emrys365.github.io//favicon.ico?v=1654523321020">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href="https://unpkg.com/papercss@1.6.1/dist/paper.min.css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://emrys365.github.io//styles/main.css">


  
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css" />
  

  

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>


<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />


  </head>
  <body>
  
    <nav class="navbar border fixed split-nav">
  <div class="nav-brand">
    <h3><a href="https://emrys365.github.io/">Speech 101</a></h3>
  </div>
  <div class="collapsible">
    <input id="collapsible1" type="checkbox" name="collapsible1">
    <button>
      <label for="collapsible1">
        <div class="bar1"></div>
        <div class="bar2"></div>
        <div class="bar3"></div>
      </label>
    </button>
    <div class="collapsible-body">
      <ul class="inline">
        
          <li>
            
              <a href="/" class="menu">
                首页
              </a>
            
          </li>
        
          <li>
            
              <a href="/archives" class="menu">
                归档
              </a>
            
          </li>
        
          <li>
            
              <a href="/tags" class="menu">
                标签
              </a>
            
          </li>
        
          <li>
            
              <a href="/post/about" class="menu">
                关于
              </a>
            
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div id="top" class="row site">
      <div class="sm-12 md-8 col">
        <div class="paper">
          <article class="article">
            <h1>ASRU历年最佳论文</h1>
            <p class="article-meta">
              2019-12-25
              
                <a href="https://emrys365.github.io/tag/ksXtoWiu7" class="badge ">
                  ASRU
                </a>
              
            </p>
            
              <img src="https://emrys365.github.io//post-images/asru-li-nian-zui-jia-lun-wen.jpg" alt="ASRU历年最佳论文">
            
            <div class="post-content">
              <h1 id="asru">ASRU</h1>
<ul>
<li>
<p>2019 年<br>
时间：2019年12月14日~18日<br>
地点：新加坡 圣淘沙<br>
共收到 299 篇投稿，最终接收 144 篇论文</p>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Incremental Lattice Determinization For WFST Decoders</td>
<td>Zhehuai Chen, Mahsa Yarmohammadi, Hainan Xu, Hang Lv, Lei Xie, Daniel Povey, Sanjeev Khudanpur</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Integrating Source-Channel and Attention-Based Sequence-to-Sequence Models for Speech Recognition</td>
<td>Qiujia Li, Chao Zhang, and Philip C. Woodland</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>3</td>
<td>End-to-End Neural Speaker Diarization with Self-Attention</td>
<td>Yusuke Fujita, Naoyuki Kanda, Shota Horiguchi, Yawen Xue, Kenji Nagamatsu, Shinji Watanabe</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Orthogonality Constrained Multi-Head Attention for Keyword Spotting</td>
<td>Mingu Lee, Jinkyu Lee, Hye Jin Jang, Byeonggeun Kim, Wonil Chang, Kyuwoong Hwang</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>MIMO-Speech: End-to-End Multi-Channel Multi-Speaker Speech Recognition</td>
<td>Xuankai Chang, Wangyou Zhang, Yanmin Qian, Jonathan Le Roux, Shinji Watanabe</td>
<td>最佳论文</td>
</tr>
<tr>
<td>6</td>
<td>Speaker and Language Aware Training for End-to-End ASR</td>
<td>Shubham Bansal, Karan Malhotra, Sriram Ganapathy</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>CNN with Phonetic Attention for Text-Independent Speaker Verification</td>
<td>Tianyan Zhou, Yong Zhao, Jinyu Li, Yifan Gong, Jian Wu</td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>2017 年<br>
时间：2017年12月16日~20日<br>
地点：日本 冲绳县<br>
共收到 ? 篇投稿，最终接收 106 篇论文</p>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Streaming Small-Footprint Keyword Spotting Using Sequence-to-Sequence Models</td>
<td>Yanzhang He, Rohit Prabhavalkar, Kanishka Rao, Wei Li, Anton Bakhtin, Ian McGraw</td>
<td>最佳论文</td>
</tr>
<tr>
<td>2</td>
<td>Hierarchical Recurrent Neural Network for Story Segmentation Using Fusion of Lexical and Acoustic Features</td>
<td>Emiru Tsunoo, Ondrej Klejch, Peter Bell, Steve Renals</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>An Embedded Segmental K-Means Model for Unsupervised Segmentation and Clustering of Speech</td>
<td>Herman Kamper, Karen Livescu, Sharon Goldwater</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Composite Embedding Systems for Zerospeech2017 Track1</td>
<td>Hayato Shibata, Taku Kato, Takahiro Shinozaki, Shinji Watanabe</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Exploring Architectures, Data and Units for Streaming End-to-End Speech Recognition with RNN-Transducer</td>
<td>Kanishka Rao, Hasim Sak, Rohit Prabhavalkar</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>Exploring Neural Transducers for End-to-End Speech Recognition</td>
<td>Eric Battenberg, Jitong Chen, Rewon Child, Adam Coates, Yashesh Gaur, Yi Li, Hairong Liu, Sanjeev Satheesh, Anuroop Sriram, Zhenyao Zhu</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Unsupervised Adaptation with Domain Separation Networks for Robust Speech Recognition</td>
<td>Zhong Meng, Zhuo Chen, Vadim Mazalov, Jinyu Li, Yifan Gong</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Language Independent End-to-End Architecture for Joint Language Identification and Speech Recognition</td>
<td>Shinji Watanabe, Takaaki Hori, John Hershey</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Multi-Level Language Modeling and Decoding for Open Vocabulary End-to-End Speech Recognition</td>
<td>Takaaki Hori, Shinji Watanabe, John Hershey</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>Listening While Speaking: Speech Chain by Deep Learning</td>
<td>Andros Tjandra, Sakriani Sakti, Satoshi Nakamura</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>11</td>
<td>Unsupervised Domain Adaptation for Robust Speech Recognition Via Variational Autoencoder-Based Data Augmentation</td>
<td>Wei-Ning Hsu, Yu Zhang, James Glass</td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>2015 年</p>
<p>时间：2015年12月13日~17日<br>
地点：美国 斯科茨代尔<br>
共收到 224 篇投稿，最终接收 107 篇论文</p>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Hybrid DNN-Latent Structured SVM Acoustic models for Continuous Speech Recognition</td>
<td>Suman Ravuri</td>
<td>最佳论文</td>
</tr>
<tr>
<td>2</td>
<td></td>
<td></td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>3</td>
<td>EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding</td>
<td>Yajie Miao, Mohammad Gowayyed, Florian Metze</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Policy Committee for Adaptation in Multi-Domain Spoken Dialogue Systems</td>
<td>M. Gašić, N. Mrkšić, Pei-hao Su, David Vandyke, Tsung-Hsien Wen, Steve Young</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>(待补充)</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>2013 年</p>
<p>时间：2013年12月8日~13日<br>
地点：捷克 奥洛穆茨</p>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Unsupervised Induction and Filling of Semantic Slots for Spoken Dialogue Systems using Frame-Semantic Parsing</td>
<td>Yun-Nung Chen, William Yang Wang, Alexander I. Rudnicky</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>2</td>
<td>A Hierarchical System for Word Discovery Exploiting Dtw-Based Initialization</td>
<td>Oliver Walter, Timo Korthals, Reinhold Haeb-Umbach, Bhiksha Raj</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>3</td>
<td>The Tao of ATWV: Probing the Mysteries of Keyword Search Performance</td>
<td>Steven Wegmann, Arlo Faria, Adam Janin, Korbinian Riedhammer, Nelson Morgan</td>
<td>最佳论文</td>
</tr>
<tr>
<td>4</td>
<td>Convolutional Neural Network Based Triangular CRF for Joint Intent Detection and Slot Filling</td>
<td>Puyang Xu, Ruhi Sarikaya</td>
<td>最佳论文</td>
</tr>
<tr>
<td>5</td>
<td>(待补充)</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>2011 年</p>
<p>时间：2011年12月11日~15日<br>
地点：美国 夏威夷岛</p>
</li>
<li>
<p>2009 年</p>
<p>时间：2009年12月13日~17日<br>
地点：意大利 梅拉诺</p>
</li>
<li>
<p>2007 年</p>
<p>时间：2007年12月9日~13日<br>
地点：日本 京都</p>
</li>
</ul>

            </div>
          </article>
        </div>
        <div class="paper" data-aos="fade-in">
          
            <div class="next-post">
              <div class="next">
                下一篇
              </div>
              <a href="https://emrys365.github.io/post/interspeech-li-nian-zui-jia-lun-wen">
                <h3 class="post-title">
                  InterSpeech历年最佳论文
                </h3>
              </a>
            </div>
          
        </div>
        
          
            <div class="paper" data-aos="fade-in">
              <div id="gitalk-container"></div>
            </div>
          

          
        
      </div>

      <div class="sm-12 md-4 col sidebar">
  <div class="paper info-container">
    <img src="https://emrys365.github.io//images/avatar.png?v=1654523321020" class="no-responsive avatar">
    <div class="text-muted">记录、学习、分享语音相关知识</div>
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
  </div>
  <div class="paper">
    <div class="sidebar-title">
      最新文章
    </div>
    <div class="row">
      <ul>
        
          
            <li>
              <a href="https://emrys365.github.io/post/debug-gu-shi-01">Debug 故事 01</a>
            </li>
          
        
          
            <li>
              <a href="https://emrys365.github.io/post/ti-jiao-arxiv-wen-zhang-de-latexyu-chu-li-ji-qiao">提交 arXiv 文章的（LaTeX）预处理技巧</a>
            </li>
          
        
          
            <li>
              <a href="https://emrys365.github.io/post/icassp-li-nian-zui-jia-lun-wen">ICASSP 历年最佳论文</a>
            </li>
          
        
          
            <li>
              <a href="https://emrys365.github.io/post/asru-li-nian-zui-jia-lun-wen">ASRU历年最佳论文</a>
            </li>
          
        
          
            <li>
              <a href="https://emrys365.github.io/post/interspeech-li-nian-zui-jia-lun-wen">InterSpeech历年最佳论文</a>
            </li>
          
        
          
            <li>
              <a href="https://emrys365.github.io/post/about">关于</a>
            </li>
          
        
      </ul>
    </div>
  </div>
  <div class="paper">
    <div class="sidebar-title">
      标签列表
    </div>
    <div class="row">
      
        <a href="https://emrys365.github.io/tag/VJeFbhl6l" class="badge success">
          debug
        </a>
      
        <a href="https://emrys365.github.io/tag/DezWZyODfQ" class="badge secondary">
          pytorch
        </a>
      
        <a href="https://emrys365.github.io/tag/rajKPAyuaM" class="badge warning">
          espnet
        </a>
      
        <a href="https://emrys365.github.io/tag/yGSS2rN9O" class="badge secondary">
          LaTeX
        </a>
      
        <a href="https://emrys365.github.io/tag/ksXtoWiu7" class="badge secondary">
          ASRU
        </a>
      
        <a href="https://emrys365.github.io/tag/EJoWkpT7N" class="badge warning">
          InterSpeech
        </a>
      
        <a href="https://emrys365.github.io/tag/Cye6SEe-V3" class="badge secondary">
          ISCA
        </a>
      
    </div>
  </div>
  <div class="paper">
    Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://emrys365.github.io//atom.xml" target="_blank">RSS</a>
  </div>
</div>


    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>

<script type="application/javascript">

AOS.init();

hljs.initHighlightingOnLoad()

</script>



  
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>

      var gitalk = new Gitalk({
        clientID: '28cd080097329ea0c788',
        clientSecret: '8d7414a55b033e9be3c55ec36b22ad9a21300d64',
        repo: 'Emrys365.github.io',
        owner: 'Emrys365',
        admin: ['Emrys365'],
        id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
        distractionFreeMode: false  // Facebook-like distraction free mode
      })

      gitalk.render('gitalk-container')

    </script>
  

  




  </body>
</html>
