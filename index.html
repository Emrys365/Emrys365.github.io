<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Speech 101</title>
<meta name="description" content="记录、学习、分享语音相关知识" />
<link rel="shortcut icon" href="https://emrys365.github.io//favicon.ico?v=1664170897068">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://emrys365.github.io//styles/main.css">

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-155032470-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-155032470-1');
</script>


  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://emrys365.github.io/">
  <img class="avatar" src="https://emrys365.github.io//images/avatar.png?v=1664170897068" alt="">
  </a>
  <h1 class="site-title">
    Speech 101
  </h1>
  <p class="site-description">
    记录、学习、分享语音相关知识
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
        <a href="https://github.com/Emrys365" target="_blank">
          <i class="fab fa-github"></i>
        </a>
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

    
        <div class="post-container">
  
    <article class="post">
      <a href="https://emrys365.github.io/post/debug-gu-shi-01">
        <h2 class="post-title">Debug 故事 01</h2>
      </a>
      <div class="post-info">
        <span>
          2022-06-06
        </span>
        <span>
          13 min read
        </span>
        
          <a href="https://emrys365.github.io/tag/VJeFbhl6l" class="post-tag">
            # debug
          </a>
        
          <a href="https://emrys365.github.io/tag/DezWZyODfQ" class="post-tag">
            # pytorch
          </a>
        
          <a href="https://emrys365.github.io/tag/rajKPAyuaM" class="post-tag">
            # espnet
          </a>
        
      </div>
      
        <a href="https://emrys365.github.io/post/debug-gu-shi-01" class="post-feature-image" style="background-image: url('https://emrys365.github.io//post-images/debug-gu-shi-01.jpeg')">
        </a>
      
      <div class="post-abstract">
        <blockquote>
<p>警告：为方便阅读，本文部分代码实为伪代码，请勿当真。</p>
</blockquote>
<h2 id="背景">背景</h2>
<p>最近我用 espnet 跑了一个比较慢的基线实验，采用 SNR loss 进行训练，虽然用上了单机 4 卡（2080ti）依然需要一周左右的时间才能完成。在基线的基础上，我希望调整一下模型训练过程，以便进行后续拓展：</p>
<ul>
<li>在计算 SNR loss 前对当前 batch 的标签进行判断，如果存在<strong>全零项</strong>，就用 L1 loss 函数来代替，因为 SNR loss 在标签为全零时无法计算。</li>
</ul>
<p>于是，我对原先的 loss 计算代码</p>
<pre><code class="language-python">loss, stats = 0.0, {}
...
loss_ = snr_loss(speech_ref, speech_pre)
stats_ = {&quot;snr_loss&quot;: loss_}
loss += loss_
stats.update(stats_)
</code></pre>
<p>做了如下修改：</p>
<pre><code class="language-python">loss, stats = 0.0, {}
...
has_all_zero = torch.cat(speech_ref, dim=0).sum(dim=-1).eq(0).any()
if has_all_zero:
    loss_ = l1_loss(speech_ref, speech_pre)
    stats_ = {&quot;l1_loss&quot;: loss_}
else:
    loss_ = snr_loss(speech_ref, speech_pre)
    stats_ = {&quot;snr_loss&quot;: loss_}
loss += loss_
stats.update(stats_)
</code></pre>
<h2 id="bug">Bug?</h2>
<p>上面的修改看似应该没有任何问题，于是我开始了模型训练。然而在检查模型的训练日志时，我发现了一个令人震惊的事实，那就是日志显示模型的 l1_loss 始终都是负的！这在理论上是绝不可能的，因为 L1 loss 是绝对值。</p>

      </div>
    </article>
  
    <article class="post">
      <a href="https://emrys365.github.io/post/ti-jiao-arxiv-wen-zhang-de-latexyu-chu-li-ji-qiao">
        <h2 class="post-title">提交 arXiv 文章的（LaTeX）预处理技巧</h2>
      </a>
      <div class="post-info">
        <span>
          2020-10-27
        </span>
        <span>
          2 min read
        </span>
        
          <a href="https://emrys365.github.io/tag/yGSS2rN9O" class="post-tag">
            # LaTeX
          </a>
        
      </div>
      
        <a href="https://emrys365.github.io/post/ti-jiao-arxiv-wen-zhang-de-latexyu-chu-li-ji-qiao" class="post-feature-image" style="background-image: url('https://emrys365.github.io//post-images/ti-jiao-arxiv-wen-zhang-de-latexyu-chu-li-ji-qiao.png')">
        </a>
      
      <div class="post-abstract">
        
      </div>
    </article>
  
    <article class="post">
      <a href="https://emrys365.github.io/post/icassp-li-nian-zui-jia-lun-wen">
        <h2 class="post-title">ICASSP 历年最佳论文</h2>
      </a>
      <div class="post-info">
        <span>
          2020-05-06
        </span>
        <span>
          1 min read
        </span>
        
      </div>
      
        <a href="https://emrys365.github.io/post/icassp-li-nian-zui-jia-lun-wen" class="post-feature-image" style="background-image: url('https://emrys365.github.io//post-images/icassp-li-nian-zui-jia-lun-wen.jpeg')">
        </a>
      
      <div class="post-abstract">
        
      </div>
    </article>
  
    <article class="post">
      <a href="https://emrys365.github.io/post/asru-li-nian-zui-jia-lun-wen">
        <h2 class="post-title">ASRU历年最佳论文</h2>
      </a>
      <div class="post-info">
        <span>
          2019-12-25
        </span>
        <span>
          5 min read
        </span>
        
          <a href="https://emrys365.github.io/tag/ksXtoWiu7" class="post-tag">
            # ASRU
          </a>
        
      </div>
      
        <a href="https://emrys365.github.io/post/asru-li-nian-zui-jia-lun-wen" class="post-feature-image" style="background-image: url('https://emrys365.github.io//post-images/asru-li-nian-zui-jia-lun-wen.jpg')">
        </a>
      
      <div class="post-abstract">
        
      </div>
    </article>
  
    <article class="post">
      <a href="https://emrys365.github.io/post/interspeech-li-nian-zui-jia-lun-wen">
        <h2 class="post-title">InterSpeech 历年最佳论文</h2>
      </a>
      <div class="post-info">
        <span>
          2019-12-25
        </span>
        <span>
          24 min read
        </span>
        
          <a href="https://emrys365.github.io/tag/EJoWkpT7N" class="post-tag">
            # InterSpeech
          </a>
        
          <a href="https://emrys365.github.io/tag/Cye6SEe-V3" class="post-tag">
            # ISCA
          </a>
        
      </div>
      
        <a href="https://emrys365.github.io/post/interspeech-li-nian-zui-jia-lun-wen" class="post-feature-image" style="background-image: url('https://emrys365.github.io//post-images/interspeech-li-nian-zui-jia-lun-wen.jpg')">
        </a>
      
      <div class="post-abstract">
        <h1 id="interspeech">InterSpeech</h1>
<p>（主要数据来源：每年会议的 AbstractBook.pdf）</p>
<ul>
<li>2022 年<br>
时间：2022 年 9 月 18 日 ~ 22 日<br>
地点：韩国 仁川（线下/远程混合会议）<br>
共收到 2490 篇投稿，其中 2140 篇被审稿，最终接收 1102 篇论文</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Trajectories Predicted by Optimal Speech Motor Control Using LSTM Networks</td>
<td>Tsiky Rakotomalala, Pierre Baraduc, Pascal Perrier</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>Transfer Learning Framework for Low-Resource Text-toSpeech Using a Large-Scale Unlabeled Speech Corpus</td>
<td>Minchan Kim, Myeonghun Jeong, Byoung Jin ChoiA, Sunghwan Ahn, Joun Yeop Lee, Nam Soo Kim</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>Pharyngealization in Amazigh: Acoustic and Articulatory Marking Over Time</td>
<td>Tsiky Rakotomalala, Pierre Baraduc, Pascal Perrier</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Tree-constrained Pointer Generator with Graph Neural Network Encodings for Contextual Speech Recognition</td>
<td>Guangzhi Sun, Chao Zhang, Phil Woodland</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Where's the Uh, Hesitation? the Interplay between Filled Pause Location, Speech Rate and Fundamental Frequency in Perception of Confidence</td>
<td>Ambika Kirkland, Harm Lameris, Éva Székely, Joakim Gustafson</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>Deep Residual Spiking Neural Network for Keyword Spotting in Low-Resource Settings</td>
<td>Qu Yang, Qi Liu, Haizhou Li</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Attentive Feature Fusion for Robust Speaker Verification</td>
<td>Bei Liu, Zhengyang Chen, Yanmin Qian</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>Robust Self-Supervised Audio-Visual Speech Recognition</td>
<td>Bowen Shi, Wei-Ning Hsu, Abdelrahman Mohamed</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td>Distance-Based Sound Separation</td>
<td>Katharine Patterson, Kevin Wilson, Scott Wisdom, John R. Hershey</td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>Investigating Perception of Spoken Dialogue Acceptability through Surprisal</td>
<td>Sarenne Carrol Wallbridge, Catherine Lai, Peter Bell</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>11</td>
<td>Complex-Valued Time-Frequency Self-Attention for Speech Dereverberation</td>
<td>Vinay Kothapally, John H.L. Hansen</td>
<td></td>
</tr>
<tr>
<td>12</td>
<td>Learning Audio-Text Agreement for Open-vocabulary Keyword Spotting</td>
<td>Hyeon-Kyeong Shin, Hyewon Han, Doyeon Kim, SooWhan Chung, Hong-Goo Kang</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>2021 年<br>
时间：2021 年 8 月 30日 ~ 9 月 3 日<br>
地点：捷克 布尔诺（远程会议）<br>
共收到 2277 篇投稿，其中 1990 篇被审稿，最终接收 963 篇论文</li>
</ul>
<style>
table th:first-of-type {  #first表示表格第一列
    width: 100px; # 可使用%比例
}
</style>
<table>
<thead>
<tr>
<th><div style="width:35px">序号</div></th>
<th>最佳学生论文（提名）</th>
<th>作者</th>
<th><div style="width:120px">获奖情况</div></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>StarGANv2-VC: A Diverse, Unsupervised, Non-parallel Framework for  NaturalSounding Voice Conversion</td>
<td>Yinghao Li, Ali Zare, Nima Mesgarani</td>
<td>最佳学生论文</td>
</tr>
<tr>
<td>2</td>
<td>Stochastic Process Regression for  Cross-Cultural Speech Emotion Recognition</td>
<td>Mani Kumar Tellamekala, Enrique Sanchez, Georgios Tzimiropoulos, Timo Giesbrecht, Michel Valstar</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>Multilingual Transfer of Acoustic Word Embeddings Improves When Training on Languages Related to the Target Zero-Resource Language</td>
<td>Christiaan Jacobs, Herman Kamper</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>Effective Phase Encoding for End-to-end Speaker Verification</td>
<td>Junyi Peng, Xiaoyang Qu, Rongzhi Gu, Jianzong Wang, Jing Xiao, Lukas Burget, Jan Černocký</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>Dialogue Situation Recognition for  Everyday Conversation Using Multimodal Information</td>
<td>Yuya Chiba, Ryuichiro Higashinaka</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>Audio Retrieval with Natural Language Queries</td>
<td>Andreea-Maria Oncescu, A. Sophia Koepke, João Henriques, Zeynep Akata, Samuel Albanie</td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>Optimally Encoding Inductive Biases into the Transformer Improves End-to-End Speech Translation</td>
<td>Piyush Vyas, Anastasia Kuznetsova, Donald Williamson</td>
<td>最佳学生论文</td>
</tr>
</tbody>
</table>

      </div>
    </article>
  
</div>

    
        <div class="pagination-container">
  
  
</div>

    
        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | 
  <a class="rss" href="https://emrys365.github.io//atom.xml" target="_blank">RSS</a>
</div>

<script>
  hljs.initHighlightingOnLoad()

  let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

  // This should probably be throttled.
  // Especially because it triggers during smooth scrolling.
  // https://lodash.com/docs/4.17.10#throttle
  // You could do like...
  // window.addEventListener("scroll", () => {
  //    _.throttle(doThatStuff, 100);
  // });
  // Only not doing it here to keep this Pen dependency-free.

  window.addEventListener("scroll", event => {
    let fromTop = window.scrollY;

    mainNavLinks.forEach((link, index) => {
      let section = document.getElementById(decodeURI(link.hash).substring(1));
      let nextSection = null
      if (mainNavLinks[index + 1]) {
        nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
      }
      if (section.offsetTop <= fromTop) {
        if (nextSection) {
          if (nextSection.offsetTop > fromTop) {
            link.classList.add("current");
          } else {
            link.classList.remove("current");    
          }
        } else {
          link.classList.add("current");
        }
      } else {
        link.classList.remove("current");
      }
    });
  });

</script>

      </div>
    </div>
  </body>
</html>
